{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J32yFYlStosX",
        "outputId": "7ac97527-a4a9-4680-d2c8-8d990803aefa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu117\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter  # For visualization\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "c9ApbkCEvfRQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define download path (optional):\n",
        "data_dir = '/content/my_data'  # Replace with your desired path\n"
      ],
      "metadata": {
        "id": "fxzDDoPCv1aH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the training and test datasets:\n",
        "train_dataset = datasets.MNIST(root=data_dir, train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vlyam9JwFk4",
        "outputId": "43593d2b-6f54-4e31-98e3-d74fc1df9f6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/my_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 131548724.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/my_data/MNIST/raw/train-images-idx3-ubyte.gz to /content/my_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/my_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 81737985.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/my_data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/my_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/my_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 38810805.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/my_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/my_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/my_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 16979080.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/my_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/my_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFeasRuVIxx9",
        "outputId": "7e0e7fb4-c9b8-4ecc-ad56-b1b68d506626"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /content/my_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and transform the MNIST datasets\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize pixel values to [0, 1]\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root=data_dir, train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST(root=data_dir, train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Create Dataloaders for training and testing\n",
        "batch_size = 64  # Adjust as needed\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Print dataset sizes (optional)\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nds_yhvuyALl",
        "outputId": "dc50a26b-dc71-447f-a7ea-6874c52d1ec5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 60000\n",
            "Test dataset size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(in_features=7 * 7 * 64, out_features=128)  # Fully connected layer\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=10)  # Output layer for 10 digits\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))  # ReLU activation after Conv1 and pooling\n",
        "    x = self.pool(torch.relu(self.conv2(x)))  # ReLU activation after Conv2 and pooling\n",
        "    x = x.view(-1, 7 * 7 * 64)  # Flatten the output of the convolutional layers\n",
        "    x = torch.relu(self.fc1(x))  # ReLU activation in the fully connected layer\n",
        "    x = self.fc2(x)  # Output layer\n",
        "    return x\n",
        "\n",
        "# Create an instance of the CNN model\n",
        "model = CNN()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHZ5Q-5P56FE",
        "outputId": "70443131-f26d-46de-f504-f82146488055"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Commonly used for multi-class classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Initialize tensorboard writer for visualization (optional)\n",
        "writer = SummaryWriter(\"runs/mnist_cnn\")  # Create a directory named \"runs/mnist_cnn\"\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # Get inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # Zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, compute loss\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate average epoch loss\n",
        "  epoch_loss = running_loss / len(train_dataset)\n",
        "\n",
        "  # Track and visualize loss (optional)\n",
        "  writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
        "\n",
        "  # Print training statistics\n",
        "  print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# ... (Code for testing and evaluation - not included here for brevity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GuHzLIrh915",
        "outputId": "0f2316d4-d3ab-4740-e2d8-a45cac00f0a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Loss: 0.0021\n",
            "Epoch [2/10] - Loss: 0.0007\n",
            "Epoch [3/10] - Loss: 0.0004\n",
            "Epoch [4/10] - Loss: 0.0003\n",
            "Epoch [5/10] - Loss: 0.0003\n",
            "Epoch [6/10] - Loss: 0.0002\n",
            "Epoch [7/10] - Loss: 0.0002\n",
            "Epoch [8/10] - Loss: 0.0001\n",
            "Epoch [9/10] - Loss: 0.0001\n",
            "Epoch [10/10] - Loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, test_dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "    for data in test_dataloader:\n",
        "      images, labels = data\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)  # Get the index of the maximum value\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  accuracy = correct / total\n",
        "  return accuracy\n",
        "\n",
        "# Test the model\n",
        "test_accuracy = calculate_accuracy(model, test_dataloader)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# ... (Optional code for visualizing predictions)\n",
        "\n",
        "# Get a few samples from the test dataset\n",
        "images, labels = next(iter(test_dataloader))\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "# Display images and predicted labels\n",
        "num_images = 4\n",
        "for i in range(num_images):\n",
        "  plt.subplot(2, num_images, i + 1)\n",
        "  plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
        "  plt.title(f\"Predicted: {predicted[i]}\")\n",
        "  plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "4bKkjTQx_QL_",
        "outputId": "76dd8076-9cab-4115-83c2-990ec6d3d3bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9913\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}